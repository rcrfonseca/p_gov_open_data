{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Crawler API Onibus Rio - CSV Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 01: <-\n",
    "    * Busca conteÃºdo da API da Prefeitura do Rio de 60 em 60 segundos.\n",
    "    * Salva arquivo .csv e realiza append a cada 60 segundos no arquivo .csv\n",
    "    * Create HTTP and Json exceptions <-\n",
    "# Version 02:\n",
    "    * Drop all duplicates.\n",
    "    * Define time to cut data to write into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, time, json, pandas as pd, requests as req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_wait():\n",
    "    time.sleep(60);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logerrorpath = '/data/dumps/log-errors/'\n",
    "csvfile = '/data/dumps/datario-bus/datariobus.csv'\n",
    "url = 'http://dadosabertos.rio.rj.gov.br/apiTransporte/apresentacao/rest/index.cfm/obterTodasPosicoes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def remove_duplicates(df):\n",
    "    df = pd.DataFrame\n",
    "    global df_total\n",
    "    df_total = pd.DataFrame\n",
    "    df_total.append(df)    \n",
    "    df_total.drop_duplicates(keep=\"first\",inplace=True)\n",
    "    return df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP or Connection Error: Expecting value: line 1 column 1 (char 0)\n",
      " Aguardar_proxima_tentativa_de_conexao \n",
      " ==========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "continua=1\n",
    "rodada = 0\n",
    "while (continua==1):\n",
    "        try:\n",
    "            response = req.get(url)\n",
    "            json_api = response.json()\n",
    "            json_header = json_api['COLUMNS']\n",
    "            json_data = json_api['DATA']\n",
    "            df = pd.DataFrame(json_data, columns=json_header)\n",
    "            #remove_duplicates(df)\n",
    "            #df_min_ant\n",
    "            #start_exec = time.strftime('%Y%m%d')\n",
    "            #if ((df.shape==df_min_ant.shape) and (df_min_ant.DATAHORA.values[len(df)-1] == df.DATAHORA.values[len(df)-1])):\n",
    "            if (rodada == 0):\n",
    "                with open(csvfile, \"w\") as fcsv:\n",
    "                    #df_total['DATAHORA'] = pd.to_datetime(df_total['DATAHORA'])\n",
    "                    df.set_index('DATAHORA', inplace=True)\n",
    "                    df.to_csv(fcsv,sep=\";\")\n",
    "                    rodada = rodada+1\n",
    "            else:\n",
    "                with open(csvfile, \"a+\") as fcsv:\n",
    "                    #df_total = df_total.append(df,sort=False)\n",
    "                    #df_total.drop_duplicates(keep=\"first\",inplace=True)\n",
    "                    #df_total['DATAHORA'] = pd.to_datetime(df_total['DATAHORA'])\n",
    "                    df.set_index('DATAHORA', inplace=True)\n",
    "                    df.to_csv(fcsv,sep=\";\",header=None)\n",
    "                    rodada = rodada+1\n",
    "        except (Exception, req.exceptions.HTTPError) as httpError:\n",
    "            http_error_time = time.strftime('%Y%m%d-%H%M%S')       \n",
    "            with open(logerrorpath+'datario-http-error-msg.txt','+a') as f:\n",
    "                f.write(\"%a\\n%a\\n%a\\n==========\\n\" % (http_error_time, str(response), str(httpError)))\n",
    "            print (\"HTTP or Connection Error: \" + str(httpError) + '\\n Aguardar_proxima_tentativa_de_conexao \\n ==========\\n')\n",
    "            pass\n",
    "        except (Exception, json.JSONDecodeError) as jsonError:\n",
    "            json_error_time = time.strftime('%Y%m%d-%H%M%S')       \n",
    "            with open(logerrorpath+'datario-json-error-msg.txt','+a') as f:\n",
    "                f.write(\"%a\\n%a\\n%a\\n==========\\n\" % (json_error_time, str(response), str(jsonError)))\n",
    "            print (\"JSON Error: \" + str(jsonError) + '\\n Aguardar_proximo_bloco_de_dados \\n ==========\\n')\n",
    "            pass\n",
    "        finally:\n",
    "            window_wait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
